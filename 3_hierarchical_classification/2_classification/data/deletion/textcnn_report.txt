sys:1: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.

***** macro: *****
 — f1: 0.888768 — precision: 0.889184 — recall: 0.889342 - accuracy: 0.889342

***** micro: *****
 — f1: 0.889342 — precision: 0.889342 — recall: 0.889342 - accuracy: 0.889342

Epoch 00001: val_f1 improved from -inf to 0.88934, saving model to ./checkpoints/textcnn/weights.01-0.8893.hdf5

***** macro: *****
 — f1: 0.898853 — precision: 0.899410 — recall: 0.899211 - accuracy: 0.899211

***** micro: *****
 — f1: 0.899211 — precision: 0.899211 — recall: 0.899211 - accuracy: 0.899211

Epoch 00002: val_f1 improved from 0.88934 to 0.89921, saving model to ./checkpoints/textcnn/weights.02-0.8992.hdf5

***** macro: *****
 — f1: 0.901472 — precision: 0.902211 — recall: 0.901974 - accuracy: 0.901974

***** micro: *****
 — f1: 0.901974 — precision: 0.901974 — recall: 0.901974 - accuracy: 0.901974

Epoch 00003: val_f1 improved from 0.89921 to 0.90197, saving model to ./checkpoints/textcnn/weights.03-0.9020.hdf5

***** macro: *****
 — f1: 0.906500 — precision: 0.907213 — recall: 0.906842 - accuracy: 0.906842

***** micro: *****
 — f1: 0.906842 — precision: 0.906842 — recall: 0.906842 - accuracy: 0.906842

Epoch 00004: val_f1 improved from 0.90197 to 0.90684, saving model to ./checkpoints/textcnn/weights.04-0.9068.hdf5

***** macro: *****
 — f1: 0.904184 — precision: 0.904479 — recall: 0.904605 - accuracy: 0.904605

***** micro: *****
 — f1: 0.904605 — precision: 0.904605 — recall: 0.904605 - accuracy: 0.904605

Epoch 00005: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.904840 — precision: 0.905455 — recall: 0.905000 - accuracy: 0.905000

***** micro: *****
 — f1: 0.905000 — precision: 0.905000 — recall: 0.905000 - accuracy: 0.905000

Epoch 00006: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905993 — precision: 0.906325 — recall: 0.906447 - accuracy: 0.906447

***** micro: *****
 — f1: 0.906447 — precision: 0.906447 — recall: 0.906447 - accuracy: 0.906447

Epoch 00007: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.904900 — precision: 0.905307 — recall: 0.905263 - accuracy: 0.905263

***** micro: *****
 — f1: 0.905263 — precision: 0.905263 — recall: 0.905263 - accuracy: 0.905263

Epoch 00008: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.904079 — precision: 0.904961 — recall: 0.904342 - accuracy: 0.904342

***** micro: *****
 — f1: 0.904342 — precision: 0.904342 — recall: 0.904342 - accuracy: 0.904342

Epoch 00009: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.906235 — precision: 0.906608 — recall: 0.906447 - accuracy: 0.906447

***** micro: *****
 — f1: 0.906447 — precision: 0.906447 — recall: 0.906447 - accuracy: 0.906447

Epoch 00010: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905265 — precision: 0.905477 — recall: 0.905526 - accuracy: 0.905526

***** micro: *****
 — f1: 0.905526 — precision: 0.905526 — recall: 0.905526 - accuracy: 0.905526

Epoch 00011: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905206 — precision: 0.906234 — recall: 0.905526 - accuracy: 0.905526

***** micro: *****
 — f1: 0.905526 — precision: 0.905526 — recall: 0.905526 - accuracy: 0.905526

Epoch 00012: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.906130 — precision: 0.906449 — recall: 0.906447 - accuracy: 0.906447

***** micro: *****
 — f1: 0.906447 — precision: 0.906447 — recall: 0.906447 - accuracy: 0.906447

Epoch 00013: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.907129 — precision: 0.907678 — recall: 0.907368 - accuracy: 0.907368

***** micro: *****
 — f1: 0.907368 — precision: 0.907368 — recall: 0.907368 - accuracy: 0.907368

Epoch 00014: val_f1 improved from 0.90684 to 0.90737, saving model to ./checkpoints/textcnn/weights.14-0.9074.hdf5

***** macro: *****
 — f1: 0.906706 — precision: 0.907786 — recall: 0.907105 - accuracy: 0.907105

***** micro: *****
 — f1: 0.907105 — precision: 0.907105 — recall: 0.907105 - accuracy: 0.907105

Epoch 00015: val_f1 did not improve from 0.90737

***** macro: *****
 — f1: 0.907815 — precision: 0.908107 — recall: 0.908158 - accuracy: 0.908158

***** micro: *****
 — f1: 0.908158 — precision: 0.908158 — recall: 0.908158 - accuracy: 0.908158

Epoch 00016: val_f1 improved from 0.90737 to 0.90816, saving model to ./checkpoints/textcnn/weights.16-0.9082.hdf5

***** macro: *****
 — f1: 0.903949 — precision: 0.905053 — recall: 0.904211 - accuracy: 0.904211

***** micro: *****
 — f1: 0.904211 — precision: 0.904211 — recall: 0.904211 - accuracy: 0.904211

Epoch 00017: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904955 — precision: 0.905729 — recall: 0.905263 - accuracy: 0.905263

***** micro: *****
 — f1: 0.905263 — precision: 0.905263 — recall: 0.905263 - accuracy: 0.905263

Epoch 00018: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.907133 — precision: 0.907396 — recall: 0.907368 - accuracy: 0.907368

***** micro: *****
 — f1: 0.907368 — precision: 0.907368 — recall: 0.907368 - accuracy: 0.907368

Epoch 00019: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904561 — precision: 0.904974 — recall: 0.904868 - accuracy: 0.904868

***** micro: *****
 — f1: 0.904868 — precision: 0.904868 — recall: 0.904868 - accuracy: 0.904868

Epoch 00020: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903117 — precision: 0.904615 — recall: 0.903553 - accuracy: 0.903553

***** micro: *****
 — f1: 0.903553 — precision: 0.903553 — recall: 0.903553 - accuracy: 0.903553

Epoch 00021: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.905218 — precision: 0.905523 — recall: 0.905526 - accuracy: 0.905526

***** micro: *****
 — f1: 0.905526 — precision: 0.905526 — recall: 0.905526 - accuracy: 0.905526

Epoch 00022: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.902528 — precision: 0.903729 — recall: 0.902763 - accuracy: 0.902763

***** micro: *****
 — f1: 0.902763 — precision: 0.902763 — recall: 0.902763 - accuracy: 0.902763

Epoch 00023: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.905265 — precision: 0.906461 — recall: 0.905395 - accuracy: 0.905395

***** micro: *****
 — f1: 0.905395 — precision: 0.905395 — recall: 0.905395 - accuracy: 0.905395

Epoch 00024: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.905395 — precision: 0.906165 — recall: 0.905658 - accuracy: 0.905658

***** micro: *****
 — f1: 0.905658 — precision: 0.905658 — recall: 0.905658 - accuracy: 0.905658

Epoch 00025: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.905635 — precision: 0.906435 — recall: 0.905921 - accuracy: 0.905921

***** micro: *****
 — f1: 0.905921 — precision: 0.905921 — recall: 0.905921 - accuracy: 0.905921

Epoch 00026: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.905021 — precision: 0.905450 — recall: 0.905395 - accuracy: 0.905395

***** micro: *****
 — f1: 0.905395 — precision: 0.905395 — recall: 0.905395 - accuracy: 0.905395

Epoch 00027: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904491 — precision: 0.905411 — recall: 0.904605 - accuracy: 0.904605

***** micro: *****
 — f1: 0.904605 — precision: 0.904605 — recall: 0.904605 - accuracy: 0.904605

Epoch 00028: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904497 — precision: 0.905517 — recall: 0.904737 - accuracy: 0.904737

***** micro: *****
 — f1: 0.904737 — precision: 0.904737 — recall: 0.904737 - accuracy: 0.904737

Epoch 00029: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904366 — precision: 0.904806 — recall: 0.904737 - accuracy: 0.904737

***** micro: *****
 — f1: 0.904737 — precision: 0.904737 — recall: 0.904737 - accuracy: 0.904737

Epoch 00030: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.905161 — precision: 0.905357 — recall: 0.905526 - accuracy: 0.905526

***** micro: *****
 — f1: 0.905526 — precision: 0.905526 — recall: 0.905526 - accuracy: 0.905526

Epoch 00031: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903374 — precision: 0.904220 — recall: 0.903684 - accuracy: 0.903684

***** micro: *****
 — f1: 0.903684 — precision: 0.903684 — recall: 0.903684 - accuracy: 0.903684

Epoch 00032: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.902726 — precision: 0.903497 — recall: 0.903158 - accuracy: 0.903158

***** micro: *****
 — f1: 0.903158 — precision: 0.903158 — recall: 0.903158 - accuracy: 0.903158

Epoch 00033: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903468 — precision: 0.903832 — recall: 0.903816 - accuracy: 0.903816

***** micro: *****
 — f1: 0.903816 — precision: 0.903816 — recall: 0.903816 - accuracy: 0.903816

Epoch 00034: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903426 — precision: 0.903699 — recall: 0.903684 - accuracy: 0.903684

***** micro: *****
 — f1: 0.903684 — precision: 0.903684 — recall: 0.903684 - accuracy: 0.903684

Epoch 00035: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903851 — precision: 0.904480 — recall: 0.904079 - accuracy: 0.904079

***** micro: *****
 — f1: 0.904079 — precision: 0.904079 — recall: 0.904079 - accuracy: 0.904079

Epoch 00036: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903547 — precision: 0.904041 — recall: 0.903816 - accuracy: 0.903816

***** micro: *****
 — f1: 0.903816 — precision: 0.903816 — recall: 0.903816 - accuracy: 0.903816

Epoch 00037: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903859 — precision: 0.904407 — recall: 0.904079 - accuracy: 0.904079

***** micro: *****
 — f1: 0.904079 — precision: 0.904079 — recall: 0.904079 - accuracy: 0.904079

Epoch 00038: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904008 — precision: 0.904615 — recall: 0.904211 - accuracy: 0.904211

***** micro: *****
 — f1: 0.904211 — precision: 0.904211 — recall: 0.904211 - accuracy: 0.904211

Epoch 00039: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903207 — precision: 0.903507 — recall: 0.903553 - accuracy: 0.903553

***** micro: *****
 — f1: 0.903553 — precision: 0.903553 — recall: 0.903553 - accuracy: 0.903553

Epoch 00040: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904322 — precision: 0.904349 — recall: 0.904605 - accuracy: 0.904605

***** micro: *****
 — f1: 0.904605 — precision: 0.904605 — recall: 0.904605 - accuracy: 0.904605

Epoch 00041: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903634 — precision: 0.904287 — recall: 0.903947 - accuracy: 0.903947

***** micro: *****
 — f1: 0.903947 — precision: 0.903947 — recall: 0.903947 - accuracy: 0.903947

Epoch 00042: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903751 — precision: 0.904286 — recall: 0.904079 - accuracy: 0.904079

***** micro: *****
 — f1: 0.904079 — precision: 0.904079 — recall: 0.904079 - accuracy: 0.904079

Epoch 00043: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.903958 — precision: 0.905101 — recall: 0.904211 - accuracy: 0.904211

***** micro: *****
 — f1: 0.904211 — precision: 0.904211 — recall: 0.904211 - accuracy: 0.904211

Epoch 00044: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.906087 — precision: 0.906398 — recall: 0.906316 - accuracy: 0.906316

***** micro: *****
 — f1: 0.906316 — precision: 0.906316 — recall: 0.906316 - accuracy: 0.906316

Epoch 00045: val_f1 did not improve from 0.90816

***** macro: *****
 — f1: 0.904396 — precision: 0.904734 — recall: 0.904737 - accuracy: 0.904737

***** micro: *****
 — f1: 0.904737 — precision: 0.904737 — recall: 0.904737 - accuracy: 0.904737

Epoch 00046: val_f1 did not improve from 0.90816
