
***** macro: *****
 — f1: 0.899867 — precision: 0.900932 — recall: 0.900000 - accuracy: 0.900000

***** micro: *****
 — f1: 0.900000 — precision: 0.900000 — recall: 0.900000 - accuracy: 0.900000

Epoch 00001: val_f1 improved from -inf to 0.90000, saving model to ./checkpoints/textrnn/weights.01-0.9000.hdf5

***** macro: *****
 — f1: 0.901501 — precision: 0.903067 — recall: 0.901842 - accuracy: 0.901842

***** micro: *****
 — f1: 0.901842 — precision: 0.901842 — recall: 0.901842 - accuracy: 0.901842

Epoch 00002: val_f1 improved from 0.90000 to 0.90184, saving model to ./checkpoints/textrnn/weights.02-0.9018.hdf5

***** macro: *****
 — f1: 0.899928 — precision: 0.901111 — recall: 0.900526 - accuracy: 0.900526

***** micro: *****
 — f1: 0.900526 — precision: 0.900526 — recall: 0.900526 - accuracy: 0.900526

Epoch 00003: val_f1 did not improve from 0.90184

***** macro: *****
 — f1: 0.901447 — precision: 0.902178 — recall: 0.901447 - accuracy: 0.901447

***** micro: *****
 — f1: 0.901447 — precision: 0.901447 — recall: 0.901447 - accuracy: 0.901447

Epoch 00004: val_f1 did not improve from 0.90184

***** macro: *****
 — f1: 0.903326 — precision: 0.903913 — recall: 0.903289 - accuracy: 0.903289

***** micro: *****
 — f1: 0.903289 — precision: 0.903289 — recall: 0.903289 - accuracy: 0.903289

Epoch 00005: val_f1 improved from 0.90184 to 0.90329, saving model to ./checkpoints/textrnn/weights.05-0.9033.hdf5

***** macro: *****
 — f1: 0.897924 — precision: 0.897958 — recall: 0.898026 - accuracy: 0.898026

***** micro: *****
 — f1: 0.898026 — precision: 0.898026 — recall: 0.898026 - accuracy: 0.898026

Epoch 00006: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.901369 — precision: 0.901517 — recall: 0.901579 - accuracy: 0.901579

***** micro: *****
 — f1: 0.901579 — precision: 0.901579 — recall: 0.901579 - accuracy: 0.901579

Epoch 00007: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.894391 — precision: 0.894364 — recall: 0.894474 - accuracy: 0.894474

***** micro: *****
 — f1: 0.894474 — precision: 0.894474 — recall: 0.894474 - accuracy: 0.894474

Epoch 00008: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.894151 — precision: 0.894065 — recall: 0.894342 - accuracy: 0.894342

***** micro: *****
 — f1: 0.894342 — precision: 0.894342 — recall: 0.894342 - accuracy: 0.894342

Epoch 00009: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.895096 — precision: 0.895115 — recall: 0.895263 - accuracy: 0.895263

***** micro: *****
 — f1: 0.895263 — precision: 0.895263 — recall: 0.895263 - accuracy: 0.895263

Epoch 00010: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.890665 — precision: 0.890558 — recall: 0.890789 - accuracy: 0.890789

***** micro: *****
 — f1: 0.890789 — precision: 0.890789 — recall: 0.890789 - accuracy: 0.890789

Epoch 00011: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.890515 — precision: 0.890475 — recall: 0.890789 - accuracy: 0.890789

***** micro: *****
 — f1: 0.890789 — precision: 0.890789 — recall: 0.890789 - accuracy: 0.890789

Epoch 00012: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.889723 — precision: 0.889713 — recall: 0.889868 - accuracy: 0.889868

***** micro: *****
 — f1: 0.889868 — precision: 0.889868 — recall: 0.889868 - accuracy: 0.889868

Epoch 00013: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.893540 — precision: 0.893519 — recall: 0.893684 - accuracy: 0.893684

***** micro: *****
 — f1: 0.893684 — precision: 0.893684 — recall: 0.893684 - accuracy: 0.893684

Epoch 00014: val_f1 did not improve from 0.90329

***** macro: *****
 — f1: 0.893285 — precision: 0.893363 — recall: 0.893553 - accuracy: 0.893553

***** micro: *****
 — f1: 0.893553 — precision: 0.893553 — recall: 0.893553 - accuracy: 0.893553

Epoch 00015: val_f1 did not improve from 0.90329
