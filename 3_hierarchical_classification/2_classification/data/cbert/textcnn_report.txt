sys:1: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.

***** macro: *****
 — f1: 0.891498 — precision: 0.892687 — recall: 0.891842 - accuracy: 0.891842

***** micro: *****
 — f1: 0.891842 — precision: 0.891842 — recall: 0.891842 - accuracy: 0.891842

Epoch 00001: val_f1 improved from -inf to 0.89184, saving model to ./checkpoints/textcnn/weights.01-0.8918.hdf5

***** macro: *****
 — f1: 0.899493 — precision: 0.900181 — recall: 0.900000 - accuracy: 0.900000

***** micro: *****
 — f1: 0.900000 — precision: 0.900000 — recall: 0.900000 - accuracy: 0.900000

Epoch 00002: val_f1 improved from 0.89184 to 0.90000, saving model to ./checkpoints/textcnn/weights.02-0.9000.hdf5

***** macro: *****
 — f1: 0.903188 — precision: 0.904354 — recall: 0.903289 - accuracy: 0.903289

***** micro: *****
 — f1: 0.903289 — precision: 0.903289 — recall: 0.903289 - accuracy: 0.903289

Epoch 00003: val_f1 improved from 0.90000 to 0.90329, saving model to ./checkpoints/textcnn/weights.03-0.9033.hdf5

***** macro: *****
 — f1: 0.906561 — precision: 0.906892 — recall: 0.906842 - accuracy: 0.906842

***** micro: *****
 — f1: 0.906842 — precision: 0.906842 — recall: 0.906842 - accuracy: 0.906842

Epoch 00004: val_f1 improved from 0.90329 to 0.90684, saving model to ./checkpoints/textcnn/weights.04-0.9068.hdf5

***** macro: *****
 — f1: 0.905691 — precision: 0.906940 — recall: 0.906053 - accuracy: 0.906053

***** micro: *****
 — f1: 0.906053 — precision: 0.906053 — recall: 0.906053 - accuracy: 0.906053

Epoch 00005: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905308 — precision: 0.905874 — recall: 0.905658 - accuracy: 0.905658

***** micro: *****
 — f1: 0.905658 — precision: 0.905658 — recall: 0.905658 - accuracy: 0.905658

Epoch 00006: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.904985 — precision: 0.906074 — recall: 0.905263 - accuracy: 0.905263

***** micro: *****
 — f1: 0.905263 — precision: 0.905263 — recall: 0.905263 - accuracy: 0.905263

Epoch 00007: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905841 — precision: 0.906436 — recall: 0.906053 - accuracy: 0.906053

***** micro: *****
 — f1: 0.906053 — precision: 0.906053 — recall: 0.906053 - accuracy: 0.906053

Epoch 00008: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905488 — precision: 0.906063 — recall: 0.905789 - accuracy: 0.905789

***** micro: *****
 — f1: 0.905789 — precision: 0.905789 — recall: 0.905789 - accuracy: 0.905789

Epoch 00009: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905116 — precision: 0.906361 — recall: 0.905395 - accuracy: 0.905395

***** micro: *****
 — f1: 0.905395 — precision: 0.905395 — recall: 0.905395 - accuracy: 0.905395

Epoch 00010: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.904706 — precision: 0.905668 — recall: 0.905000 - accuracy: 0.905000

***** micro: *****
 — f1: 0.905000 — precision: 0.905000 — recall: 0.905000 - accuracy: 0.905000

Epoch 00011: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.904853 — precision: 0.905361 — recall: 0.905263 - accuracy: 0.905263

***** micro: *****
 — f1: 0.905263 — precision: 0.905263 — recall: 0.905263 - accuracy: 0.905263

Epoch 00012: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.904377 — precision: 0.905079 — recall: 0.904605 - accuracy: 0.904605

***** micro: *****
 — f1: 0.904605 — precision: 0.904605 — recall: 0.904605 - accuracy: 0.904605

Epoch 00013: val_f1 did not improve from 0.90684

***** macro: *****
 — f1: 0.905680 — precision: 0.906584 — recall: 0.905921 - accuracy: 0.905921

***** micro: *****
 — f1: 0.905921 — precision: 0.905921 — recall: 0.905921 - accuracy: 0.905921

Epoch 00014: val_f1 did not improve from 0.90684
