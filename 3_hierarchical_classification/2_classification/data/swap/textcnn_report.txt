sys:1: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.

***** macro: *****
 — f1: 0.893001 — precision: 0.893409 — recall: 0.893289 - accuracy: 0.893289

***** micro: *****
 — f1: 0.893289 — precision: 0.893289 — recall: 0.893289 - accuracy: 0.893289

Epoch 00001: val_f1 improved from -inf to 0.89329, saving model to ./checkpoints/textcnn/weights.01-0.8933.hdf5

***** macro: *****
 — f1: 0.900244 — precision: 0.901644 — recall: 0.900789 - accuracy: 0.900789

***** micro: *****
 — f1: 0.900789 — precision: 0.900789 — recall: 0.900789 - accuracy: 0.900789

Epoch 00002: val_f1 improved from 0.89329 to 0.90079, saving model to ./checkpoints/textcnn/weights.02-0.9008.hdf5

***** macro: *****
 — f1: 0.904800 — precision: 0.905894 — recall: 0.905000 - accuracy: 0.905000

***** micro: *****
 — f1: 0.905000 — precision: 0.905000 — recall: 0.905000 - accuracy: 0.905000

Epoch 00003: val_f1 improved from 0.90079 to 0.90500, saving model to ./checkpoints/textcnn/weights.03-0.9050.hdf5

***** macro: *****
 — f1: 0.905023 — precision: 0.905822 — recall: 0.905263 - accuracy: 0.905263

***** micro: *****
 — f1: 0.905263 — precision: 0.905263 — recall: 0.905263 - accuracy: 0.905263

Epoch 00004: val_f1 improved from 0.90500 to 0.90526, saving model to ./checkpoints/textcnn/weights.04-0.9053.hdf5

***** macro: *****
 — f1: 0.906037 — precision: 0.906711 — recall: 0.906316 - accuracy: 0.906316

***** micro: *****
 — f1: 0.906316 — precision: 0.906316 — recall: 0.906316 - accuracy: 0.906316

Epoch 00005: val_f1 improved from 0.90526 to 0.90632, saving model to ./checkpoints/textcnn/weights.05-0.9063.hdf5

***** macro: *****
 — f1: 0.906041 — precision: 0.906945 — recall: 0.906316 - accuracy: 0.906316

***** micro: *****
 — f1: 0.906316 — precision: 0.906316 — recall: 0.906316 - accuracy: 0.906316

Epoch 00006: val_f1 did not improve from 0.90632

***** macro: *****
 — f1: 0.907161 — precision: 0.907621 — recall: 0.907500 - accuracy: 0.907500

***** micro: *****
 — f1: 0.907500 — precision: 0.907500 — recall: 0.907500 - accuracy: 0.907500

Epoch 00007: val_f1 improved from 0.90632 to 0.90750, saving model to ./checkpoints/textcnn/weights.07-0.9075.hdf5

***** macro: *****
 — f1: 0.906367 — precision: 0.907410 — recall: 0.906711 - accuracy: 0.906711

***** micro: *****
 — f1: 0.906711 — precision: 0.906711 — recall: 0.906711 - accuracy: 0.906711

Epoch 00008: val_f1 did not improve from 0.90750

***** macro: *****
 — f1: 0.907136 — precision: 0.907721 — recall: 0.907500 - accuracy: 0.907500

***** micro: *****
 — f1: 0.907500 — precision: 0.907500 — recall: 0.907500 - accuracy: 0.907500

Epoch 00009: val_f1 did not improve from 0.90750

***** macro: *****
 — f1: 0.907701 — precision: 0.908285 — recall: 0.908026 - accuracy: 0.908026

***** micro: *****
 — f1: 0.908026 — precision: 0.908026 — recall: 0.908026 - accuracy: 0.908026

Epoch 00010: val_f1 improved from 0.90750 to 0.90803, saving model to ./checkpoints/textcnn/weights.10-0.9080.hdf5

***** macro: *****
 — f1: 0.906824 — precision: 0.907291 — recall: 0.907105 - accuracy: 0.907105

***** micro: *****
 — f1: 0.907105 — precision: 0.907105 — recall: 0.907105 - accuracy: 0.907105

Epoch 00011: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.905448 — precision: 0.906522 — recall: 0.905789 - accuracy: 0.905789

***** micro: *****
 — f1: 0.905789 — precision: 0.905789 — recall: 0.905789 - accuracy: 0.905789

Epoch 00012: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.903991 — precision: 0.904980 — recall: 0.904342 - accuracy: 0.904342

***** micro: *****
 — f1: 0.904342 — precision: 0.904342 — recall: 0.904342 - accuracy: 0.904342

Epoch 00013: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.907170 — precision: 0.907806 — recall: 0.907500 - accuracy: 0.907500

***** micro: *****
 — f1: 0.907500 — precision: 0.907500 — recall: 0.907500 - accuracy: 0.907500

Epoch 00014: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.904128 — precision: 0.905741 — recall: 0.904474 - accuracy: 0.904474

***** micro: *****
 — f1: 0.904474 — precision: 0.904474 — recall: 0.904474 - accuracy: 0.904474

Epoch 00015: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.903987 — precision: 0.904795 — recall: 0.904211 - accuracy: 0.904211

***** micro: *****
 — f1: 0.904211 — precision: 0.904211 — recall: 0.904211 - accuracy: 0.904211

Epoch 00016: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.906105 — precision: 0.906607 — recall: 0.906447 - accuracy: 0.906447

***** micro: *****
 — f1: 0.906447 — precision: 0.906447 — recall: 0.906447 - accuracy: 0.906447

Epoch 00017: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.906178 — precision: 0.906839 — recall: 0.906447 - accuracy: 0.906447

***** micro: *****
 — f1: 0.906447 — precision: 0.906447 — recall: 0.906447 - accuracy: 0.906447

Epoch 00018: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.903261 — precision: 0.904836 — recall: 0.903553 - accuracy: 0.903553

***** micro: *****
 — f1: 0.903553 — precision: 0.903553 — recall: 0.903553 - accuracy: 0.903553

Epoch 00019: val_f1 did not improve from 0.90803

***** macro: *****
 — f1: 0.905416 — precision: 0.906181 — recall: 0.905658 - accuracy: 0.905658

***** micro: *****
 — f1: 0.905658 — precision: 0.905658 — recall: 0.905658 - accuracy: 0.905658

Epoch 00020: val_f1 did not improve from 0.90803
