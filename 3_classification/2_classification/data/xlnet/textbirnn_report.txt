sys:1: FutureWarning: arrays to stack must be passed as a "sequence" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.

***** macro: *****
 — f1: 0.890654 — precision: 0.891954 — recall: 0.890921 - accuracy: 0.890921

***** micro: *****
 — f1: 0.890921 — precision: 0.890921 — recall: 0.890921 - accuracy: 0.890921

Epoch 00001: val_f1 improved from -inf to 0.89092, saving model to ./checkpoints/textcnn/weights.01-0.8909.hdf5

***** macro: *****
 — f1: 0.902071 — precision: 0.902814 — recall: 0.902368 - accuracy: 0.902368

***** micro: *****
 — f1: 0.902368 — precision: 0.902368 — recall: 0.902368 - accuracy: 0.902368

Epoch 00002: val_f1 improved from 0.89092 to 0.90237, saving model to ./checkpoints/textcnn/weights.02-0.9024.hdf5

***** macro: *****
 — f1: 0.903102 — precision: 0.905484 — recall: 0.903289 - accuracy: 0.903289

***** micro: *****
 — f1: 0.903289 — precision: 0.903289 — recall: 0.903289 - accuracy: 0.903289

Epoch 00003: val_f1 improved from 0.90237 to 0.90329, saving model to ./checkpoints/textcnn/weights.03-0.9033.hdf5

***** macro: *****
 — f1: 0.903187 — precision: 0.904391 — recall: 0.903553 - accuracy: 0.903553

***** micro: *****
 — f1: 0.903553 — precision: 0.903553 — recall: 0.903553 - accuracy: 0.903553

Epoch 00004: val_f1 improved from 0.90329 to 0.90355, saving model to ./checkpoints/textcnn/weights.04-0.9036.hdf5

***** macro: *****
 — f1: 0.905297 — precision: 0.905726 — recall: 0.905658 - accuracy: 0.905658

***** micro: *****
 — f1: 0.905658 — precision: 0.905658 — recall: 0.905658 - accuracy: 0.905658

Epoch 00005: val_f1 improved from 0.90355 to 0.90566, saving model to ./checkpoints/textcnn/weights.05-0.9057.hdf5

***** macro: *****
 — f1: 0.904365 — precision: 0.905585 — recall: 0.904737 - accuracy: 0.904737

***** micro: *****
 — f1: 0.904737 — precision: 0.904737 — recall: 0.904737 - accuracy: 0.904737

Epoch 00006: val_f1 did not improve from 0.90566

***** macro: *****
 — f1: 0.905115 — precision: 0.905858 — recall: 0.905395 - accuracy: 0.905395

***** micro: *****
 — f1: 0.905395 — precision: 0.905395 — recall: 0.905395 - accuracy: 0.905395

Epoch 00007: val_f1 did not improve from 0.90566

***** macro: *****
 — f1: 0.903215 — precision: 0.903954 — recall: 0.903553 - accuracy: 0.903553

***** micro: *****
 — f1: 0.903553 — precision: 0.903553 — recall: 0.903553 - accuracy: 0.903553

Epoch 00008: val_f1 did not improve from 0.90566

***** macro: *****
 — f1: 0.902731 — precision: 0.903934 — recall: 0.903158 - accuracy: 0.903158

***** micro: *****
 — f1: 0.903158 — precision: 0.903158 — recall: 0.903158 - accuracy: 0.903158

Epoch 00009: val_f1 did not improve from 0.90566

***** macro: *****
 — f1: 0.905630 — precision: 0.906260 — recall: 0.905921 - accuracy: 0.905921

***** micro: *****
 — f1: 0.905921 — precision: 0.905921 — recall: 0.905921 - accuracy: 0.905921

Epoch 00010: val_f1 improved from 0.90566 to 0.90592, saving model to ./checkpoints/textcnn/weights.10-0.9059.hdf5

***** macro: *****
 — f1: 0.904457 — precision: 0.905354 — recall: 0.904737 - accuracy: 0.904737

***** micro: *****
 — f1: 0.904737 — precision: 0.904737 — recall: 0.904737 - accuracy: 0.904737

Epoch 00011: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.904403 — precision: 0.905954 — recall: 0.904605 - accuracy: 0.904605

***** micro: *****
 — f1: 0.904605 — precision: 0.904605 — recall: 0.904605 - accuracy: 0.904605

Epoch 00012: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.904132 — precision: 0.905479 — recall: 0.904474 - accuracy: 0.904474

***** micro: *****
 — f1: 0.904474 — precision: 0.904474 — recall: 0.904474 - accuracy: 0.904474

Epoch 00013: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.903059 — precision: 0.905456 — recall: 0.903289 - accuracy: 0.903289

***** micro: *****
 — f1: 0.903289 — precision: 0.903289 — recall: 0.903289 - accuracy: 0.903289

Epoch 00014: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.904063 — precision: 0.905247 — recall: 0.904342 - accuracy: 0.904342

***** micro: *****
 — f1: 0.904342 — precision: 0.904342 — recall: 0.904342 - accuracy: 0.904342

Epoch 00015: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.903433 — precision: 0.904997 — recall: 0.903816 - accuracy: 0.903816

***** micro: *****
 — f1: 0.903816 — precision: 0.903816 — recall: 0.903816 - accuracy: 0.903816

Epoch 00016: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.904326 — precision: 0.905664 — recall: 0.904737 - accuracy: 0.904737

***** micro: *****
 — f1: 0.904737 — precision: 0.904737 — recall: 0.904737 - accuracy: 0.904737

Epoch 00017: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.905090 — precision: 0.905693 — recall: 0.905395 - accuracy: 0.905395

***** micro: *****
 — f1: 0.905395 — precision: 0.905395 — recall: 0.905395 - accuracy: 0.905395

Epoch 00018: val_f1 did not improve from 0.90592

***** macro: *****
 — f1: 0.905821 — precision: 0.906344 — recall: 0.906184 - accuracy: 0.906184

***** micro: *****
 — f1: 0.906184 — precision: 0.906184 — recall: 0.906184 - accuracy: 0.906184

Epoch 00019: val_f1 improved from 0.90592 to 0.90618, saving model to ./checkpoints/textcnn/weights.19-0.9062.hdf5

***** macro: *****
 — f1: 0.904215 — precision: 0.905328 — recall: 0.904474 - accuracy: 0.904474

***** micro: *****
 — f1: 0.904474 — precision: 0.904474 — recall: 0.904474 - accuracy: 0.904474

Epoch 00020: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.903788 — precision: 0.904757 — recall: 0.904211 - accuracy: 0.904211

***** micro: *****
 — f1: 0.904211 — precision: 0.904211 — recall: 0.904211 - accuracy: 0.904211

Epoch 00021: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.904868 — precision: 0.905719 — recall: 0.905132 - accuracy: 0.905132

***** micro: *****
 — f1: 0.905132 — precision: 0.905132 — recall: 0.905132 - accuracy: 0.905132

Epoch 00022: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.905266 — precision: 0.906354 — recall: 0.905658 - accuracy: 0.905658

***** micro: *****
 — f1: 0.905658 — precision: 0.905658 — recall: 0.905658 - accuracy: 0.905658

Epoch 00023: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.902982 — precision: 0.904292 — recall: 0.903289 - accuracy: 0.903289

***** micro: *****
 — f1: 0.903289 — precision: 0.903289 — recall: 0.903289 - accuracy: 0.903289

Epoch 00024: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.902929 — precision: 0.904000 — recall: 0.903421 - accuracy: 0.903421

***** micro: *****
 — f1: 0.903421 — precision: 0.903421 — recall: 0.903421 - accuracy: 0.903421

Epoch 00025: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.903946 — precision: 0.904731 — recall: 0.904342 - accuracy: 0.904342

***** micro: *****
 — f1: 0.904342 — precision: 0.904342 — recall: 0.904342 - accuracy: 0.904342

Epoch 00026: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.903959 — precision: 0.904961 — recall: 0.904211 - accuracy: 0.904211

***** micro: *****
 — f1: 0.904211 — precision: 0.904211 — recall: 0.904211 - accuracy: 0.904211

Epoch 00027: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.903454 — precision: 0.904042 — recall: 0.903816 - accuracy: 0.903816

***** micro: *****
 — f1: 0.903816 — precision: 0.903816 — recall: 0.903816 - accuracy: 0.903816

Epoch 00028: val_f1 did not improve from 0.90618

***** macro: *****
 — f1: 0.904156 — precision: 0.905160 — recall: 0.904474 - accuracy: 0.904474

***** micro: *****
 — f1: 0.904474 — precision: 0.904474 — recall: 0.904474 - accuracy: 0.904474

Epoch 00029: val_f1 did not improve from 0.90618
